{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13467935,"sourceType":"datasetVersion","datasetId":8549366}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install sentence-transformers","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T09:34:39.946451Z","iopub.execute_input":"2025-11-26T09:34:39.947287Z","iopub.status.idle":"2025-11-26T09:35:52.722837Z","shell.execute_reply.started":"2025-11-26T09:34:39.947238Z","shell.execute_reply":"2025-11-26T09:35:52.721791Z"},"_kg_hide-output":true},"outputs":[{"name":"stdout","text":"Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (4.1.0)\nRequirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.53.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\nRequirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.2.2)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.15.3)\nRequirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.36.0)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.3.0)\nRequirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.15.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.20.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.10.0)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.3)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.5)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.11.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.2)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.5.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (2.4.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.10.5)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.2.0)\nDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m104.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m72.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m57.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m78.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# Library imported","metadata":{}},{"cell_type":"code","source":"import os\nimport re\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader, TensorDataset\nimport torch.optim as optim\n\nfrom nltk.corpus import stopwords \nfrom collections import Counter\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import PorterStemmer\nfrom torch.nn.utils.rnn import pad_sequence\nimport string\n\nfrom tqdm import tqdm\n\nfrom sklearn.model_selection import train_test_split\nfrom sentence_transformers import SentenceTransformer\nfrom sklearn.preprocessing import LabelEncoder\n\nis_cuda = torch.cuda.is_available()\n\n# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\nif is_cuda:\n    device = torch.device(\"cuda\")\n    print(\"GPU is available\")\nelse:\n    device = torch.device(\"cpu\")\n    print(\"GPU not available, CPU used\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-26T09:36:00.480224Z","iopub.execute_input":"2025-11-26T09:36:00.480575Z","iopub.status.idle":"2025-11-26T09:36:38.243548Z","shell.execute_reply.started":"2025-11-26T09:36:00.480543Z","shell.execute_reply":"2025-11-26T09:36:38.242448Z"}},"outputs":[{"name":"stderr","text":"2025-11-26 09:36:16.043313: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1764149776.263191      47 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1764149776.327998      47 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"name":"stdout","text":"GPU is available\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"# SentenceTransformer (all-MiniLM-L6-v2) from Huggingface","metadata":{}},{"cell_type":"code","source":"embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")   # 384-dim embeddings\nEMB_SIZE = embedder.get_sentence_embedding_dimension()\nprint(\"Embedding size:\", EMB_SIZE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T09:37:03.476762Z","iopub.execute_input":"2025-11-26T09:37:03.477601Z","iopub.status.idle":"2025-11-26T09:37:11.330018Z","shell.execute_reply.started":"2025-11-26T09:37:03.477572Z","shell.execute_reply":"2025-11-26T09:37:11.329310Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e9e96c51acc9494eae2c9b3341bb9063"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"99bd169d790441b784610e6ed53a4c37"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6875ce6855c94de999779d61eaa0d869"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c45761da4a0847069c337eb34984fd40"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"377259cfee8b4069b344f15dc528b7bd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b5b49bf8bc8f4c73b99dc78fabf96f27"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe83d8ee3f784d2c871a5ea9ca097004"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d25c96fe7158456b9c626500999e5ece"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"979692a4041244d2a236433487ad8689"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e7c01ccadf984a8e989156a5916a8fc8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2bbf5ec515304647b5858ff8fa4b221f"}},"metadata":{}},{"name":"stdout","text":"Embedding size: 384\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/mobile-reviews-sentiment-and-specification/Mobile Reviews Sentiment.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T09:37:14.857342Z","iopub.execute_input":"2025-11-26T09:37:14.857613Z","iopub.status.idle":"2025-11-26T09:37:15.200899Z","shell.execute_reply.started":"2025-11-26T09:37:14.857595Z","shell.execute_reply":"2025-11-26T09:37:15.200295Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"df.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T09:37:19.581278Z","iopub.execute_input":"2025-11-26T09:37:19.581584Z","iopub.status.idle":"2025-11-26T09:37:19.587661Z","shell.execute_reply.started":"2025-11-26T09:37:19.581549Z","shell.execute_reply":"2025-11-26T09:37:19.586919Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"(50000, 25)"},"metadata":{}}],"execution_count":5},{"cell_type":"markdown","source":"# Clean Text Preprocessing Function","metadata":{}},{"cell_type":"code","source":"def clean_text(text):\n    # remove html\n    text = re.sub(r\"<.*?>\", \"\", text)\n    # remove url\n    text = re.sub(r\"http\\S+\", \"\", text)\n    # remove punctuation + emoji\n    text = re.sub(r\"[^A-Za-z0-9\\s]\", \"\", text)\n    # remove digits\n    text = re.sub(r\"\\d+\", \"\", text)\n    # normalize spaces\n    text = re.sub(r\"\\s+\", \" \", text)\n    # lower case\n    text = text.lower().strip()\n    return text\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T09:37:23.584466Z","iopub.execute_input":"2025-11-26T09:37:23.585123Z","iopub.status.idle":"2025-11-26T09:37:23.589451Z","shell.execute_reply.started":"2025-11-26T09:37:23.585096Z","shell.execute_reply":"2025-11-26T09:37:23.588718Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"# Dataset : returns sequence of embeddings\n\nWe use SBERT’s tokenizer internally to get subword tokens, then embed each token separately → resulting in a sequence.","metadata":{}},{"cell_type":"code","source":"class HybridEmbeddingDataset(Dataset):\n    def __init__(self, texts, labels, embedder):\n        self.texts = [clean_text(t) for t in texts]\n        self.labels = labels\n        self.embedder = embedder\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        text = self.texts[idx]\n\n        # Get token-level embeddings (not pooled)\n        token_embeddings = self.embedder.encode(\n            text,\n            output_value=\"token_embeddings\",      # <-- IMPORTANT\n            convert_to_tensor=True\n        )  # shape: (seq_len, 384)\n\n        label = torch.tensor(self.labels[idx], dtype=torch.long)\n\n        return token_embeddings, label\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T09:37:28.381897Z","iopub.execute_input":"2025-11-26T09:37:28.382181Z","iopub.status.idle":"2025-11-26T09:37:28.387824Z","shell.execute_reply.started":"2025-11-26T09:37:28.382159Z","shell.execute_reply":"2025-11-26T09:37:28.387213Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"# Collate function for padding","metadata":{}},{"cell_type":"code","source":"def collate_batch(batch):\n    sequences = [item[0] for item in batch]\n    labels = torch.tensor([item[1] for item in batch], dtype=torch.long)\n\n    # Pad sequences to same length\n    padded = nn.utils.rnn.pad_sequence(sequences, batch_first=True)\n\n    return padded, labels\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T09:37:33.597378Z","iopub.execute_input":"2025-11-26T09:37:33.598078Z","iopub.status.idle":"2025-11-26T09:37:33.602376Z","shell.execute_reply.started":"2025-11-26T09:37:33.598050Z","shell.execute_reply":"2025-11-26T09:37:33.601495Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"texts = df[\"review_text\"].astype(str)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T09:37:49.174555Z","iopub.execute_input":"2025-11-26T09:37:49.175207Z","iopub.status.idle":"2025-11-26T09:37:49.184996Z","shell.execute_reply.started":"2025-11-26T09:37:49.175175Z","shell.execute_reply":"2025-11-26T09:37:49.184104Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"texts","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T09:37:51.392114Z","iopub.execute_input":"2025-11-26T09:37:51.392402Z","iopub.status.idle":"2025-11-26T09:37:51.399700Z","shell.execute_reply.started":"2025-11-26T09:37:51.392383Z","shell.execute_reply":"2025-11-26T09:37:51.398965Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"0           Not worth the money spent. Wouldn’t recommend.\n1        Absolutely love this phone! The camera is next...\n2        Loving the clean UI and fast updates. Loving i...\n3        Build quality feels solid and durable. No regr...\n4        Not bad for daily use but could be optimized. ...\n                               ...                        \n49995    Battery easily lasts a day with heavy use. Lov...\n49996    Battery life could be slightly better. Fine bu...\n49997    Face unlock is instant, super smooth. Best pur...\n49998    Build quality feels solid and durable. Loving ...\n49999    Loving the clean UI and fast updates. Loving i...\nName: review_text, Length: 50000, dtype: object"},"metadata":{}}],"execution_count":11},{"cell_type":"markdown","source":"# train test split ","metadata":{}},{"cell_type":"code","source":"y = df[\"sentiment\"]\ny","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T09:38:11.390440Z","iopub.execute_input":"2025-11-26T09:38:11.391192Z","iopub.status.idle":"2025-11-26T09:38:11.397898Z","shell.execute_reply.started":"2025-11-26T09:38:11.391165Z","shell.execute_reply":"2025-11-26T09:38:11.396977Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"0        Negative\n1        Positive\n2        Positive\n3        Positive\n4         Neutral\n           ...   \n49995    Positive\n49996     Neutral\n49997    Positive\n49998    Positive\n49999    Positive\nName: sentiment, Length: 50000, dtype: object"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"le = LabelEncoder()\ny_enc = le.fit_transform(y)\nprint(y_enc[:10])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T09:40:08.222598Z","iopub.execute_input":"2025-11-26T09:40:08.223196Z","iopub.status.idle":"2025-11-26T09:40:08.235395Z","shell.execute_reply.started":"2025-11-26T09:40:08.223175Z","shell.execute_reply":"2025-11-26T09:40:08.234483Z"}},"outputs":[{"name":"stdout","text":"[0 2 2 2 1 2 2 0 2 2]\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"x_train,x_test,y_train,y_test = train_test_split(texts,y_enc,test_size=0.15, random_state=12)\n\nx_train.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T09:40:56.988738Z","iopub.execute_input":"2025-11-26T09:40:56.989024Z","iopub.status.idle":"2025-11-26T09:40:56.999545Z","shell.execute_reply.started":"2025-11-26T09:40:56.989003Z","shell.execute_reply":"2025-11-26T09:40:56.998649Z"}},"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"(42500,)"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"\ntrain_dataset = HybridEmbeddingDataset(x_train, y_train, embedder)\ntest_dataset  = HybridEmbeddingDataset(x_test,  y_test,  embedder)\n\ntrain_loader = DataLoader(train_dataset, batch_size=512, shuffle=True, collate_fn=collate_batch)\ntest_loader  = DataLoader(test_dataset,  batch_size=512, shuffle=False, collate_fn=collate_batch)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T09:41:17.623207Z","iopub.execute_input":"2025-11-26T09:41:17.623541Z","iopub.status.idle":"2025-11-26T09:41:18.072757Z","shell.execute_reply.started":"2025-11-26T09:41:17.623522Z","shell.execute_reply":"2025-11-26T09:41:18.072078Z"}},"outputs":[],"execution_count":22},{"cell_type":"markdown","source":"# Hybrid Model (BiLSTM + Attention)","metadata":{}},{"cell_type":"code","source":"class BiLSTM_Attention(nn.Module):\n    def __init__(self, embed_dim=384, hidden_dim=256, num_classes=3):\n        super().__init__()\n        \n        self.lstm = nn.LSTM(\n            embed_dim, \n            hidden_dim, \n            batch_first=True,\n            bidirectional=True\n        )\n\n        # Attention layer\n        self.attention = nn.Linear(hidden_dim * 2, 1)\n\n        # Final classifier\n        self.fc = nn.Sequential(\n            nn.Linear(hidden_dim * 2, 256),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(256, num_classes)\n        )\n\n    def forward(self, x):\n        lstm_out, _ = self.lstm(x)   # (B, L, 512)\n\n        # Attention weights\n        attn_weights = F.softmax(self.attention(lstm_out), dim=1)  # (B, L, 1)\n\n        # Context vector: sum(LSTM_out * attention_weights)\n        context = torch.sum(attn_weights * lstm_out, dim=1)  # (B, 512)\n\n        return self.fc(context)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T09:42:30.242730Z","iopub.execute_input":"2025-11-26T09:42:30.243030Z","iopub.status.idle":"2025-11-26T09:42:30.250756Z","shell.execute_reply.started":"2025-11-26T09:42:30.243009Z","shell.execute_reply":"2025-11-26T09:42:30.249986Z"}},"outputs":[],"execution_count":23},{"cell_type":"markdown","source":"# LSTM model taining","metadata":{}},{"cell_type":"code","source":"model = BiLSTM_Attention().to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T09:42:35.929730Z","iopub.execute_input":"2025-11-26T09:42:35.930043Z","iopub.status.idle":"2025-11-26T09:42:35.988197Z","shell.execute_reply.started":"2025-11-26T09:42:35.930023Z","shell.execute_reply":"2025-11-26T09:42:35.987610Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"def train_model(model, train_loader, val_loader, epochs=5):\n    model.train()\n\n    for epoch in range(epochs):\n        total_loss = 0\n        correct = 0\n        total = 0\n\n        for X_batch, y_batch in tqdm(train_loader):\n            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n\n            optimizer.zero_grad()\n            outputs = model(X_batch)\n            loss = criterion(outputs, y_batch)\n            loss.backward()\n            optimizer.step()\n\n            total_loss += loss.item()\n            pred = outputs.argmax(1)\n            correct += (pred == y_batch).sum().item()\n            total += y_batch.size(0)\n\n        train_acc = correct / total\n\n        # ---- Validation ----\n        model.eval()\n        val_correct = 0\n        val_total = 0\n\n        with torch.no_grad():\n            for X_batch, y_batch in tqdm(val_loader):\n                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n                outputs = model(X_batch)\n                pred = outputs.argmax(1)\n\n                val_correct += (pred == y_batch).sum().item()\n                val_total += y_batch.size(0)\n\n        val_acc = val_correct / val_total\n        model.train()\n\n        print(f\"Epoch {epoch+1}/{epochs} | Loss: {total_loss:.3f} | \"\n              f\"Train Acc: {train_acc:.3f} | Val Acc: {val_acc:.3f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T09:42:42.927078Z","iopub.execute_input":"2025-11-26T09:42:42.927918Z","iopub.status.idle":"2025-11-26T09:42:42.934470Z","shell.execute_reply.started":"2025-11-26T09:42:42.927891Z","shell.execute_reply":"2025-11-26T09:42:42.933825Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"train_model(model, train_loader, test_loader, epochs=5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T09:42:59.268887Z","iopub.execute_input":"2025-11-26T09:42:59.269420Z","iopub.status.idle":"2025-11-26T10:33:28.072626Z","shell.execute_reply.started":"2025-11-26T09:42:59.269396Z","shell.execute_reply":"2025-11-26T10:33:28.071740Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 84/84 [04:21<00:00,  3.12s/it]\n100%|██████████| 15/15 [00:46<00:00,  3.08s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/10 | Loss: 46.685 | Train Acc: 0.767 | Val Acc: 1.000\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 84/84 [04:20<00:00,  3.10s/it]\n100%|██████████| 15/15 [00:45<00:00,  3.02s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2/10 | Loss: 0.274 | Train Acc: 1.000 | Val Acc: 1.000\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 84/84 [04:15<00:00,  3.04s/it]\n100%|██████████| 15/15 [00:44<00:00,  2.95s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3/10 | Loss: 0.045 | Train Acc: 1.000 | Val Acc: 1.000\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 84/84 [04:13<00:00,  3.02s/it]\n100%|██████████| 15/15 [00:44<00:00,  2.98s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4/10 | Loss: 0.022 | Train Acc: 1.000 | Val Acc: 1.000\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 84/84 [04:14<00:00,  3.03s/it]\n100%|██████████| 15/15 [00:44<00:00,  2.95s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5/10 | Loss: 0.013 | Train Acc: 1.000 | Val Acc: 1.000\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 84/84 [04:12<00:00,  3.01s/it]\n100%|██████████| 15/15 [00:44<00:00,  2.94s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6/10 | Loss: 0.009 | Train Acc: 1.000 | Val Acc: 1.000\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 84/84 [04:11<00:00,  2.99s/it]\n100%|██████████| 15/15 [00:44<00:00,  2.94s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 7/10 | Loss: 0.007 | Train Acc: 1.000 | Val Acc: 1.000\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 84/84 [04:28<00:00,  3.20s/it]\n100%|██████████| 15/15 [00:48<00:00,  3.22s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8/10 | Loss: 0.005 | Train Acc: 1.000 | Val Acc: 1.000\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 84/84 [04:18<00:00,  3.08s/it]\n100%|██████████| 15/15 [00:46<00:00,  3.10s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 9/10 | Loss: 0.004 | Train Acc: 1.000 | Val Acc: 1.000\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 84/84 [04:18<00:00,  3.07s/it]\n100%|██████████| 15/15 [00:45<00:00,  3.04s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 10/10 | Loss: 0.003 | Train Acc: 1.000 | Val Acc: 1.000\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":26},{"cell_type":"markdown","source":"# Inference","metadata":{}},{"cell_type":"code","source":"def predict_sentiment(text):\n    model.eval()\n\n    text = clean_text(text)\n\n    token_emb = embedder.encode(\n        text, \n        output_value=\"token_embeddings\",\n        convert_to_tensor=True\n    ).unsqueeze(0).to(device)   # (1, L, 384)\n\n    logits = model(token_emb)\n    pred = torch.argmax(logits, dim=1).item()\n\n    mapping = [\"Negative\",\"Neutral\",\"Positive\"]  #  numeric to string\n    return mapping[pred]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T10:35:01.457321Z","iopub.execute_input":"2025-11-26T10:35:01.458060Z","iopub.status.idle":"2025-11-26T10:35:01.462407Z","shell.execute_reply.started":"2025-11-26T10:35:01.458033Z","shell.execute_reply":"2025-11-26T10:35:01.461781Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"predict_sentiment(\" phone service very bad\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T10:35:36.990526Z","iopub.execute_input":"2025-11-26T10:35:36.990814Z","iopub.status.idle":"2025-11-26T10:35:37.006747Z","shell.execute_reply.started":"2025-11-26T10:35:36.990794Z","shell.execute_reply":"2025-11-26T10:35:37.006144Z"}},"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"'Negative'"},"metadata":{}}],"execution_count":33},{"cell_type":"markdown","source":"# Save the Model (Recommended Way)","metadata":{}},{"cell_type":"code","source":"def save_model(model, path=\"sentiment_model.pth\", label2id=None, config=None):\n    save_dict = {\n        \"model_state_dict\": model.state_dict(),\n        # \"label2id\": label2id,\n        # \"config\": config\n    }\n    torch.save(save_dict, path)\n    print(f\"Model saved to {path}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T10:37:29.595030Z","iopub.execute_input":"2025-11-26T10:37:29.595415Z","iopub.status.idle":"2025-11-26T10:37:29.599965Z","shell.execute_reply.started":"2025-11-26T10:37:29.595391Z","shell.execute_reply":"2025-11-26T10:37:29.599055Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"# config = {\n#     \"embedding_dim\": 384,\n#     \"hidden_dim\": 256,\n#     \"num_classes\": 3,\n# }\n\n# label2id = {\"negative\": 0,  \"neutral\": 1, \"positive\": 2}\n\nsave_model(model, \"hybrid_sentiment.pth\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T10:37:33.527152Z","iopub.execute_input":"2025-11-26T10:37:33.527645Z","iopub.status.idle":"2025-11-26T10:37:33.547902Z","shell.execute_reply.started":"2025-11-26T10:37:33.527622Z","shell.execute_reply":"2025-11-26T10:37:33.547166Z"}},"outputs":[{"name":"stdout","text":"Model saved to hybrid_sentiment.pth\n","output_type":"stream"}],"execution_count":39},{"cell_type":"code","source":"def load_model(model_class, path=\"sentiment_model.pth\"):\n    checkpoint = torch.load(path, map_location=\"cpu\")\n    \n    # Rebuild model with stored config\n   # model = model_class(**checkpoint[\"config\"])\n    model.load_state_dict(checkpoint[\"model_state_dict\"])\n    model.eval()\n\n    # label2id = checkpoint[\"label2id\"]\n    # id2label = {v: k for k, v in label2id.items()}\n\n    return model\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T10:38:02.035421Z","iopub.execute_input":"2025-11-26T10:38:02.035731Z","iopub.status.idle":"2025-11-26T10:38:02.040439Z","shell.execute_reply.started":"2025-11-26T10:38:02.035709Z","shell.execute_reply":"2025-11-26T10:38:02.039770Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"model = load_model(BiLSTM_Attention, \"hybrid_sentiment.pth\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T10:38:09.557954Z","iopub.execute_input":"2025-11-26T10:38:09.558433Z","iopub.status.idle":"2025-11-26T10:38:09.568991Z","shell.execute_reply.started":"2025-11-26T10:38:09.558409Z","shell.execute_reply":"2025-11-26T10:38:09.568291Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"from sentence_transformers import SentenceTransformer\nimport torch\n\nencoder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n\nmapping = [\"Negative\",\"Neutral\",\"Positive\"] \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T10:40:30.976998Z","iopub.execute_input":"2025-11-26T10:40:30.977615Z","iopub.status.idle":"2025-11-26T10:40:31.759580Z","shell.execute_reply.started":"2025-11-26T10:40:30.977591Z","shell.execute_reply":"2025-11-26T10:40:31.758720Z"}},"outputs":[],"execution_count":47},{"cell_type":"code","source":"def predict_text(model, text):\n    text = clean_text(text)\n\n    token_emb = encoder.encode(\n        text, \n        output_value=\"token_embeddings\",\n        convert_to_tensor=True\n    ).unsqueeze(0).to(device)   # (1, L, 384)\n\n    logits = model(token_emb)\n    pred = torch.argmax(logits, dim=1).item()\n    return mapping[pred]\n\n\nprint(predict_text(model, \"phone service given very good\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T10:42:40.323180Z","iopub.execute_input":"2025-11-26T10:42:40.323498Z","iopub.status.idle":"2025-11-26T10:42:40.339208Z","shell.execute_reply.started":"2025-11-26T10:42:40.323478Z","shell.execute_reply":"2025-11-26T10:42:40.338578Z"}},"outputs":[{"name":"stdout","text":"Negative\n","output_type":"stream"}],"execution_count":52},{"cell_type":"markdown","source":"# Export to ONNX","metadata":{}},{"cell_type":"code","source":"def export_onnx(model, filename):\n    model_cpu = model.to(\"cpu\")      # FIX 1: move model to CPU\n    model_cpu.eval()\n\n    dummy_input = torch.randn(1, 1, 384)  # SentenceTransformer output size\n                                          # already on CPU\n\n    torch.onnx.export(\n        model_cpu,\n        dummy_input,\n        filename,\n        input_names=[\"embedding\"],\n        output_names=[\"logits\"],\n        dynamic_axes={\"embedding\": {0: \"batch\", 1: \"seq_len\"}},\n        opset_version=17\n    )\n\n    print(\"Exported:\", filename)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T10:49:28.623358Z","iopub.execute_input":"2025-11-26T10:49:28.623655Z","iopub.status.idle":"2025-11-26T10:49:28.628568Z","shell.execute_reply.started":"2025-11-26T10:49:28.623632Z","shell.execute_reply":"2025-11-26T10:49:28.627700Z"}},"outputs":[],"execution_count":59},{"cell_type":"code","source":"export_onnx(model, \"hybrid_sentiment.onnx\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T10:49:32.829208Z","iopub.execute_input":"2025-11-26T10:49:32.829992Z","iopub.status.idle":"2025-11-26T10:49:33.230472Z","shell.execute_reply.started":"2025-11-26T10:49:32.829967Z","shell.execute_reply":"2025-11-26T10:49:33.229717Z"}},"outputs":[{"name":"stdout","text":"Exported: hybrid_sentiment.onnx\n","output_type":"stream"}],"execution_count":60},{"cell_type":"code","source":"!pip install onnxruntime","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T10:51:51.194783Z","iopub.execute_input":"2025-11-26T10:51:51.195360Z","iopub.status.idle":"2025-11-26T10:51:56.382276Z","shell.execute_reply.started":"2025-11-26T10:51:51.195335Z","shell.execute_reply":"2025-11-26T10:51:56.381418Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Collecting onnxruntime\n  Downloading onnxruntime-1.23.2-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\nCollecting coloredlogs (from onnxruntime)\n  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (25.2.10)\nRequirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (1.26.4)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (25.0)\nRequirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (6.33.0)\nRequirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (1.13.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.6->onnxruntime) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.6->onnxruntime) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.6->onnxruntime) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.6->onnxruntime) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.6->onnxruntime) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.6->onnxruntime) (2.4.1)\nCollecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime) (1.3.0)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.21.6->onnxruntime) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.21.6->onnxruntime) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.21.6->onnxruntime) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.21.6->onnxruntime) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.21.6->onnxruntime) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.21.6->onnxruntime) (2024.2.0)\nDownloading onnxruntime-1.23.2-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m80.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: humanfriendly, coloredlogs, onnxruntime\nSuccessfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.23.2\n","output_type":"stream"}],"execution_count":62},{"cell_type":"code","source":"import onnxruntime as ort\nimport numpy as np\nfrom sentence_transformers import SentenceTransformer\n\nencoder = SentenceTransformer(\"all-MiniLM-L6-v2\")\nort_session = ort.InferenceSession(\"hybrid_sentiment.onnx\")\nid2label = {0: \"negative\", 2: \"positive\", 1: \"neutral\"}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T10:52:00.107945Z","iopub.execute_input":"2025-11-26T10:52:00.108293Z","iopub.status.idle":"2025-11-26T10:52:01.189055Z","shell.execute_reply.started":"2025-11-26T10:52:00.108237Z","shell.execute_reply":"2025-11-26T10:52:01.188232Z"}},"outputs":[],"execution_count":63},{"cell_type":"code","source":"def predict_onnx(text):\n    # Step 1 → Encode text using SentenceTransformer\n    emb = encoder.encode([text])              # shape (1, 768)\n    emb = np.expand_dims(emb, axis=1)         # shape (1, 1, 768)\n\n    # Step 2 → Run ONNX\n    ort_inputs = {\"embedding\": emb.astype(np.float32)}\n    logits = ort_session.run(None, ort_inputs)[0]\n\n    # Step 3 → Get sentiment\n    pred = np.argmax(logits, axis=1)[0]\n    return id2label[pred]\n\nprint(predict_onnx(\"This product is very bad!\"))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T10:52:18.369729Z","iopub.execute_input":"2025-11-26T10:52:18.370346Z","iopub.status.idle":"2025-11-26T10:52:18.388258Z","shell.execute_reply.started":"2025-11-26T10:52:18.370321Z","shell.execute_reply":"2025-11-26T10:52:18.387607Z"}},"outputs":[{"name":"stdout","text":"negative\n","output_type":"stream"}],"execution_count":65},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}